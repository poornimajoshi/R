---
title: "project2_version2"
author: "poornima_joshi"
date: "12/3/2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Read the file
```{r }
setwd("~/Documents/R/android apps")h
library("foreign")
raw_data <- read.csv("clean_googleplaystore.csv")
```

Re-leveling data
```{r }
data <- raw_data
data$installations <- factor(data$Installs)
data$out <- relevel(data$installations, ref='1')
```

Now we’ll execute a multinomial regression with two independent variable.

```{r }
table(data$Installs)
set.seed(100)
trainingRows <- sample(1:nrow(data), 0.8*nrow(data))
training <- data[trainingRows, ]
test <- data[-trainingRows, ]
```

```{r}
library("nnet")
model <- multinom(out ~ ., data=training, na.action=na.omit)
summary(model)
```


Interpretation
1. Model execution output shows some iteration history and includes the final negative log-likelihood 179.981726. This value is multiplied by two as shown in the model summary as the Residual Deviance.

2. The summary output has a block of coefficients and another block of standard errors. Each blocks has one row of values corresponding to one model equation. In the block of coefficients, we see that the first row is being compared to prog = “general” to our baseline prog = “academic” and the second row to prog = “vocation” to our baseline prog = “academic”.

3. A one-unit increase in write decreases the log odds of being in general program vs. academic program by 0.0579

4. A one-unit increase in write decreases the log odds of being in vocation program vs. academic program by 0.1136

5. The log odds of being in general program than in academic program will decrease by 1.163 if moving from ses=”low” to ses=”high”.

6. On the other hand, Log odds of being in general program than in academic program will decrease by 0.5332 if moving from ses=”low” to ses=”middle”

7. The log odds of being in vocation program vs. in academic program will decrease by 0.983 if moving from ses=”low” to ses=”high”

8. The log odds of being in vocation program vs. in academic program will increase by 0.291 if moving from ses=”low” to ses=”middle”

Now we’ll calculate Z score and p-Value for the variables in the model.
```{r }
z <- summary(model)$coefficients/summary(model)$standard.errors
z

p <- (1 - pnorm(abs(z), 0, 1))*2
p

exp(coef(model))
```
The p-Value tells us that ses variables are not significant.  Now we’ll explore the entire data set, and analyze if we can remove any variables which do not add to model performance.

Let’s check for fitted values now.
```{r}
head(fitted(model))
head(model)
```

Once we have build the model, we’ll use it for prediction. Let us create a new data set with different permutation and combinations.
```{r }
vars <- c("Rating","Reviews","Size","Type")
test <- test[vars]
expanded <- test
head(expanded)
```
##   Rating Reviews Size Type
##7     3.8     178 19.0 Free
##8     4.1   36815 29.0 Free
##10    4.7     121  3.1 Free
##13    4.2   44829 20.0 Free
##14    4.6    4326 21.0 Free
##15    4.4    1518 37.0 Free

```{r }
predicted=predict(model,expanded,type="probs")
head(predicted)
```


Now, we’ll calculate the prediction values. The parameter type=”probs”, specifies our interest in probabilities. In order to plot predicted probabilities for intuitive understanding, we add predicted probability values to data.
```{r }
bpp=cbind(expanded, predicted)
```
Now we’ll calculate the mean probabilities within each level of out
```{r}
by(bpp[,4:7], bpp$out, colMeans)
```
## bpp$ses: low
##    read   write    math science 
##   50.00   47.00   51.50   47.25 
## -------------------------------------------------------- 
## bpp$ses: middle
##    read   write    math science 
##   50.00   47.00   51.50   47.25 
## -------------------------------------------------------- 
## bpp$ses: high
##    read   write    math science 
##   50.00   47.00   51.50   47.25

I’ve used the melt() function from ‘reshape2’ package. It “melts” data with the purpose of each row being a unique id-variable combination.

> library("reshape2")

## Warning: package 'reshape2' was built under R version 3.1.3

> bpp2 = melt (bpp,id.vars=c("female", "ses","schtyp", "read","write","math","science","socst","honors", "awards"),value.name="probablity")

> head(bpp2)

##   female ses schtyp read write math science socst       honors awards
## 1 female low public   20    23   30      25    30 not enrolled      0
## 2   male low public   20    23   30      25    30 not enrolled      0
## 3   male low public   20    23   30      25    30 not enrolled      0
## 4   male low public   20    23   30      25    30 not enrolled      0
## 5 female low public   20    23   30      25    30 not enrolled      0
## 6   male low public   20    23   30      25    30 not enrolled      0
##   variable probablity
## 1 academic 0.01357216
## 2 academic 0.01929452
## 3 academic 0.01929452
## 4 academic 0.01929452
## 5 academic 0.01357216
## 6 academic 0.01929452

Now, we will be plotting graphs to explore the distribution of dependent variable vs independent variables, using ggplot() function. In ggplot, the first parameter in this function is the data values to be plotted. The second part is where (aes()) binds variables to x and y axis. We tell the plotting function to draw a line using geom_line(). We are differentiating the school type by plotting them in different colors.

> library("ggplot2")

> ggplot(bpp2, aes(x = write, y = probablity, colour = ses)) +
       geom_line() + facet_grid(variable ~ ., scales="free")